07/22 16:47:55 label: default
07/22 16:47:56 description:
  default configuration
  next line of description
  last line
07/22 16:47:57 D:/AutomatedCodeDocumentation/eval-auto-code-docu/approaches/deepCom/source code/__main__.py ../config.yaml --train -v
07/22 16:48:02 commit hash a4d5b48d985a3e9f931af4702e6af488b4c49e5c
07/22 16:48:05 tensorflow version: 1.12.0
07/22 16:48:19 program arguments
07/22 16:48:21   aggregation_method   'sum'
07/22 16:48:25   align_encoder_id     0
07/22 16:48:25   allow_growth         True
07/22 16:48:25   attention_type       'global'
07/22 16:48:25   attn_filter_length   0
07/22 16:48:25   attn_filters         0
07/22 16:48:25   attn_prev_word       False
07/22 16:48:25   attn_size            128
07/22 16:48:25   attn_temperature     1.0
07/22 16:48:25   attn_window_size     0
07/22 16:48:25   average              False
07/22 16:48:25   batch_mode           'standard'
07/22 16:48:25   batch_size           64
07/22 16:48:25   beam_size            5
07/22 16:48:25   bidir                False
07/22 16:48:25   bidir_projection     False
07/22 16:48:25   binary               False
07/22 16:48:25   cell_size            256
07/22 16:48:25   cell_type            'GRU'
07/22 16:48:25   character_level      False
07/22 16:48:25   checkpoints          []
07/22 16:48:25   conditional_rnn      False
07/22 16:48:25   config               '../config.yaml'
07/22 16:48:25   convolutions         None
07/22 16:48:25   data_dir             '../emse-data'
07/22 16:48:25   debug                False
07/22 16:48:25   decay_after_n_epoch  1
07/22 16:48:25   decay_every_n_epoch  1
07/22 16:48:25   decay_if_no_progress None
07/22 16:48:25   decoders             [{'max_len': 30, 'name': 'nl'}]
07/22 16:48:25   description          'default configuration\nnext line of description\nlast line\n'
07/22 16:48:25   dev_prefix           'test'
07/22 16:48:25   early_stopping       True
07/22 16:48:25   embedding_size       256
07/22 16:48:25   embeddings_on_cpu    True
07/22 16:48:25   encoders             [{'attention_type': 'global', 'max_len': 200, 'name': 'code'},
 {'attention_type': 'global', 'max_len': 500, 'name': 'sbt'}]
07/22 16:48:25   ensemble             False
07/22 16:48:25   eval_burn_in         0
07/22 16:48:25   feed_previous        0.0
07/22 16:48:25   final_state          'last'
07/22 16:48:25   freeze_variables     []
07/22 16:48:25   generate_first       True
07/22 16:48:25   gpu_id               6
07/22 16:48:25   highway_layers       0
07/22 16:48:25   initial_state_dropout 0.0
07/22 16:48:25   initializer          None
07/22 16:48:25   input_layer_dropout  0.0
07/22 16:48:25   input_layers         None
07/22 16:48:25   keep_best            5
07/22 16:48:25   keep_every_n_hours   0
07/22 16:48:25   label                'default'
07/22 16:48:25   layer_norm           False
07/22 16:48:25   layers               1
07/22 16:48:25   learning_rate        0.5
07/22 16:48:25   learning_rate_decay_factor 0.95
07/22 16:48:25   len_normalization    1.0
07/22 16:48:25   log_file             'log.txt'
07/22 16:48:25   loss_function        'xent'
07/22 16:48:25   max_dev_size         0
07/22 16:48:25   max_epochs           100
07/22 16:48:25   max_gradient_norm    5.0
07/22 16:48:25   max_len              50
07/22 16:48:25   max_steps            600000
07/22 16:48:25   max_test_size        0
07/22 16:48:25   max_to_keep          1
07/22 16:48:25   max_train_size       0
07/22 16:48:25   maxout_stride        None
07/22 16:48:25   mem_fraction         1.0
07/22 16:48:25   min_learning_rate    1e-06
07/22 16:48:25   model_dir            '../emse-data/model/hybrid'
07/22 16:48:25   moving_average       None
07/22 16:48:25   no_gpu               False
07/22 16:48:25   optimizer            'sgd'
07/22 16:48:25   orthogonal_init      False
07/22 16:48:25   output               None
07/22 16:48:25   output_dropout       0.0
07/22 16:48:25   parallel_iterations  16
07/22 16:48:25   pervasive_dropout    False
07/22 16:48:25   pooling_avg          True
07/22 16:48:25   post_process_script  None
07/22 16:48:25   pred_deep_layer      False
07/22 16:48:25   pred_edits           False
07/22 16:48:25   pred_embed_proj      True
07/22 16:48:25   pred_maxout_layer    True
07/22 16:48:25   purge                False
07/22 16:48:25   raw_output           False
07/22 16:48:25   read_ahead           1
07/22 16:48:25   remove_unk           False
07/22 16:48:25   reverse_input        True
07/22 16:48:25   rnn_feed_attn        True
07/22 16:48:25   rnn_input_dropout    0.0
07/22 16:48:25   rnn_output_dropout   0.0
07/22 16:48:25   rnn_state_dropout    0.0
07/22 16:48:25   save                 False
07/22 16:48:25   score_function       'nltk_sentence_bleu'
07/22 16:48:25   script_dir           'scripts'
07/22 16:48:25   sgd_after_n_epoch    None
07/22 16:48:25   sgd_learning_rate    1.0
07/22 16:48:25   shuffle              True
07/22 16:48:25   softmax_temperature  1.0
07/22 16:48:25   steps_per_checkpoint 2000
07/22 16:48:25   steps_per_eval       2000
07/22 16:48:25   swap_memory          True
07/22 16:48:25   tie_embeddings       False
07/22 16:48:25   time_pooling         None
07/22 16:48:25   train                True
07/22 16:48:25   train_initial_states True
07/22 16:48:25   train_prefix         'train'
07/22 16:48:25   truncate_lines       True
07/22 16:48:25   update_first         False
07/22 16:48:25   use_dropout          False
07/22 16:48:25   use_lstm_full_state  False
07/22 16:48:25   use_previous_word    True
07/22 16:48:25   verbose              True
07/22 16:48:25   vocab_prefix         'vocab'
07/22 16:48:25   weight_scale         None
07/22 16:48:25   word_dropout         0.0
07/22 16:49:32 python random seed: 6316282066608774755
07/22 16:49:32 tf random seed:     1676796891659444974
07/22 16:50:09 creating model
07/22 16:50:10 using device: /gpu:6
07/22 16:50:23 copying vocab to ../emse-data/model/hybrid\data\vocab.code
07/22 16:52:35 label: default
07/22 16:52:35 description:
  default configuration
  next line of description
  last line
07/22 16:52:35 D:/AutomatedCodeDocumentation/eval-auto-code-docu/approaches/deepCom/source code/__main__.py ../config.yaml --train -v
07/22 16:52:35 commit hash a4d5b48d985a3e9f931af4702e6af488b4c49e5c
07/22 16:52:35 tensorflow version: 1.12.0
07/22 16:52:35 program arguments
07/22 16:52:35   aggregation_method   'sum'
07/22 16:52:35   align_encoder_id     0
07/22 16:52:35   allow_growth         True
07/22 16:52:35   attention_type       'global'
07/22 16:52:35   attn_filter_length   0
07/22 16:52:35   attn_filters         0
07/22 16:52:35   attn_prev_word       False
07/22 16:52:35   attn_size            128
07/22 16:52:35   attn_temperature     1.0
07/22 16:52:35   attn_window_size     0
07/22 16:52:35   average              False
07/22 16:52:35   batch_mode           'standard'
07/22 16:52:35   batch_size           64
07/22 16:52:35   beam_size            5
07/22 16:52:35   bidir                False
07/22 16:52:35   bidir_projection     False
07/22 16:52:35   binary               False
07/22 16:52:35   cell_size            256
07/22 16:52:35   cell_type            'GRU'
07/22 16:52:35   character_level      False
07/22 16:52:35   checkpoints          []
07/22 16:52:35   conditional_rnn      False
07/22 16:52:35   config               '../config.yaml'
07/22 16:52:35   convolutions         None
07/22 16:52:35   data_dir             '../emse-data'
07/22 16:52:35   debug                False
07/22 16:52:35   decay_after_n_epoch  1
07/22 16:52:35   decay_every_n_epoch  1
07/22 16:52:35   decay_if_no_progress None
07/22 16:52:35   decoders             [{'max_len': 30, 'name': 'nl'}]
07/22 16:52:35   description          'default configuration\nnext line of description\nlast line\n'
07/22 16:52:35   dev_prefix           'test'
07/22 16:52:35   early_stopping       True
07/22 16:52:35   embedding_size       256
07/22 16:52:35   embeddings_on_cpu    True
07/22 16:52:35   encoders             [{'attention_type': 'global', 'max_len': 200, 'name': 'code'},
 {'attention_type': 'global', 'max_len': 500, 'name': 'sbt'}]
07/22 16:52:35   ensemble             False
07/22 16:52:35   eval_burn_in         0
07/22 16:52:35   feed_previous        0.0
07/22 16:52:35   final_state          'last'
07/22 16:52:35   freeze_variables     []
07/22 16:52:35   generate_first       True
07/22 16:52:35   gpu_id               6
07/22 16:52:35   highway_layers       0
07/22 16:52:35   initial_state_dropout 0.0
07/22 16:52:35   initializer          None
07/22 16:52:35   input_layer_dropout  0.0
07/22 16:52:35   input_layers         None
07/22 16:52:35   keep_best            5
07/22 16:52:35   keep_every_n_hours   0
07/22 16:52:35   label                'default'
07/22 16:52:35   layer_norm           False
07/22 16:52:35   layers               1
07/22 16:52:35   learning_rate        0.5
07/22 16:52:35   learning_rate_decay_factor 0.95
07/22 16:52:35   len_normalization    1.0
07/22 16:52:35   log_file             'log.txt'
07/22 16:52:35   loss_function        'xent'
07/22 16:52:35   max_dev_size         0
07/22 16:52:35   max_epochs           100
07/22 16:52:35   max_gradient_norm    5.0
07/22 16:52:35   max_len              50
07/22 16:52:35   max_steps            600000
07/22 16:52:35   max_test_size        0
07/22 16:52:35   max_to_keep          1
07/22 16:52:35   max_train_size       0
07/22 16:52:35   maxout_stride        None
07/22 16:52:35   mem_fraction         1.0
07/22 16:52:35   min_learning_rate    1e-06
07/22 16:52:35   model_dir            '../emse-data/model/hybrid'
07/22 16:52:35   moving_average       None
07/22 16:52:35   no_gpu               False
07/22 16:52:35   optimizer            'sgd'
07/22 16:52:35   orthogonal_init      False
07/22 16:52:35   output               None
07/22 16:52:35   output_dropout       0.0
07/22 16:52:35   parallel_iterations  16
07/22 16:52:35   pervasive_dropout    False
07/22 16:52:35   pooling_avg          True
07/22 16:52:35   post_process_script  None
07/22 16:52:35   pred_deep_layer      False
07/22 16:52:35   pred_edits           False
07/22 16:52:35   pred_embed_proj      True
07/22 16:52:35   pred_maxout_layer    True
07/22 16:52:35   purge                False
07/22 16:52:35   raw_output           False
07/22 16:52:35   read_ahead           1
07/22 16:52:35   remove_unk           False
07/22 16:52:35   reverse_input        True
07/22 16:52:35   rnn_feed_attn        True
07/22 16:52:35   rnn_input_dropout    0.0
07/22 16:52:35   rnn_output_dropout   0.0
07/22 16:52:35   rnn_state_dropout    0.0
07/22 16:52:35   save                 False
07/22 16:52:35   score_function       'nltk_sentence_bleu'
07/22 16:52:35   script_dir           'scripts'
07/22 16:52:35   sgd_after_n_epoch    None
07/22 16:52:35   sgd_learning_rate    1.0
07/22 16:52:35   shuffle              True
07/22 16:52:35   softmax_temperature  1.0
07/22 16:52:35   steps_per_checkpoint 2000
07/22 16:52:35   steps_per_eval       2000
07/22 16:52:35   swap_memory          True
07/22 16:52:35   tie_embeddings       False
07/22 16:52:35   time_pooling         None
07/22 16:52:35   train                True
07/22 16:52:35   train_initial_states True
07/22 16:52:35   train_prefix         'train'
07/22 16:52:35   truncate_lines       True
07/22 16:52:35   update_first         False
07/22 16:52:35   use_dropout          False
07/22 16:52:35   use_lstm_full_state  False
07/22 16:52:35   use_previous_word    True
07/22 16:52:35   verbose              True
07/22 16:52:35   vocab_prefix         'vocab'
07/22 16:52:35   weight_scale         None
07/22 16:52:35   word_dropout         0.0
07/22 16:52:37 python random seed: 2332011342603232649
07/22 16:52:37 tf random seed:     2498401819254924109
07/22 16:52:37 creating model
07/22 16:52:37 using device: /gpu:6
07/22 16:52:37 copying vocab to ../emse-data/model/hybrid\data\vocab.code
07/22 17:04:50 label: default
07/22 17:04:50 description:
  default configuration
  next line of description
  last line
07/22 17:04:50 D:/AutomatedCodeDocumentation/eval-auto-code-docu/approaches/deepCom/source code/__main__.py ../config.yaml --train -v
07/22 17:04:51 commit hash a4d5b48d985a3e9f931af4702e6af488b4c49e5c
07/22 17:04:51 tensorflow version: 1.12.0
07/22 17:04:51 program arguments
07/22 17:04:51   aggregation_method   'sum'
07/22 17:04:51   align_encoder_id     0
07/22 17:04:51   allow_growth         True
07/22 17:04:51   attention_type       'global'
07/22 17:04:51   attn_filter_length   0
07/22 17:04:51   attn_filters         0
07/22 17:04:51   attn_prev_word       False
07/22 17:04:51   attn_size            128
07/22 17:04:51   attn_temperature     1.0
07/22 17:04:51   attn_window_size     0
07/22 17:04:51   average              False
07/22 17:04:51   batch_mode           'standard'
07/22 17:04:51   batch_size           64
07/22 17:04:51   beam_size            5
07/22 17:04:51   bidir                False
07/22 17:04:51   bidir_projection     False
07/22 17:04:51   binary               False
07/22 17:04:51   cell_size            256
07/22 17:04:51   cell_type            'GRU'
07/22 17:04:51   character_level      False
07/22 17:04:51   checkpoints          []
07/22 17:04:51   conditional_rnn      False
07/22 17:04:51   config               '../config.yaml'
07/22 17:04:51   convolutions         None
07/22 17:04:51   data_dir             '../emse-data'
07/22 17:04:51   debug                False
07/22 17:04:51   decay_after_n_epoch  1
07/22 17:04:51   decay_every_n_epoch  1
07/22 17:04:51   decay_if_no_progress None
07/22 17:04:51   decoders             [{'max_len': 30, 'name': 'nl'}]
07/22 17:04:51   description          'default configuration\nnext line of description\nlast line\n'
07/22 17:04:51   dev_prefix           'test'
07/22 17:04:51   early_stopping       True
07/22 17:04:51   embedding_size       256
07/22 17:04:51   embeddings_on_cpu    True
07/22 17:04:51   encoders             [{'attention_type': 'global', 'max_len': 200, 'name': 'code'},
 {'attention_type': 'global', 'max_len': 500, 'name': 'sbt'}]
07/22 17:04:51   ensemble             False
07/22 17:04:51   eval_burn_in         0
07/22 17:04:51   feed_previous        0.0
07/22 17:04:51   final_state          'last'
07/22 17:04:51   freeze_variables     []
07/22 17:04:51   generate_first       True
07/22 17:04:51   gpu_id               6
07/22 17:04:51   highway_layers       0
07/22 17:04:51   initial_state_dropout 0.0
07/22 17:04:51   initializer          None
07/22 17:04:51   input_layer_dropout  0.0
07/22 17:04:51   input_layers         None
07/22 17:04:51   keep_best            5
07/22 17:04:51   keep_every_n_hours   0
07/22 17:04:51   label                'default'
07/22 17:04:51   layer_norm           False
07/22 17:04:51   layers               1
07/22 17:04:51   learning_rate        0.5
07/22 17:04:51   learning_rate_decay_factor 0.95
07/22 17:04:51   len_normalization    1.0
07/22 17:04:51   log_file             'log.txt'
07/22 17:04:51   loss_function        'xent'
07/22 17:04:51   max_dev_size         0
07/22 17:04:51   max_epochs           100
07/22 17:04:51   max_gradient_norm    5.0
07/22 17:04:51   max_len              50
07/22 17:04:51   max_steps            600000
07/22 17:04:51   max_test_size        0
07/22 17:04:51   max_to_keep          1
07/22 17:04:51   max_train_size       0
07/22 17:04:51   maxout_stride        None
07/22 17:04:51   mem_fraction         1.0
07/22 17:04:51   min_learning_rate    1e-06
07/22 17:04:51   model_dir            '../emse-data/model/hybrid'
07/22 17:04:51   moving_average       None
07/22 17:04:51   no_gpu               False
07/22 17:04:51   optimizer            'sgd'
07/22 17:04:51   orthogonal_init      False
07/22 17:04:51   output               None
07/22 17:04:51   output_dropout       0.0
07/22 17:04:51   parallel_iterations  16
07/22 17:04:51   pervasive_dropout    False
07/22 17:04:51   pooling_avg          True
07/22 17:04:51   post_process_script  None
07/22 17:04:51   pred_deep_layer      False
07/22 17:04:51   pred_edits           False
07/22 17:04:51   pred_embed_proj      True
07/22 17:04:51   pred_maxout_layer    True
07/22 17:04:51   purge                False
07/22 17:04:51   raw_output           False
07/22 17:04:51   read_ahead           1
07/22 17:04:51   remove_unk           False
07/22 17:04:51   reverse_input        True
07/22 17:04:51   rnn_feed_attn        True
07/22 17:04:51   rnn_input_dropout    0.0
07/22 17:04:51   rnn_output_dropout   0.0
07/22 17:04:51   rnn_state_dropout    0.0
07/22 17:04:51   save                 False
07/22 17:04:51   score_function       'nltk_sentence_bleu'
07/22 17:04:51   script_dir           'scripts'
07/22 17:04:51   sgd_after_n_epoch    None
07/22 17:04:51   sgd_learning_rate    1.0
07/22 17:04:51   shuffle              True
07/22 17:04:51   softmax_temperature  1.0
07/22 17:04:51   steps_per_checkpoint 2000
07/22 17:04:51   steps_per_eval       2000
07/22 17:04:51   swap_memory          True
07/22 17:04:51   tie_embeddings       False
07/22 17:04:51   time_pooling         None
07/22 17:04:51   train                True
07/22 17:04:51   train_initial_states True
07/22 17:04:51   train_prefix         'train'
07/22 17:04:51   truncate_lines       True
07/22 17:04:51   update_first         False
07/22 17:04:51   use_dropout          False
07/22 17:04:51   use_lstm_full_state  False
07/22 17:04:51   use_previous_word    True
07/22 17:04:51   verbose              True
07/22 17:04:51   vocab_prefix         'vocab'
07/22 17:04:51   weight_scale         None
07/22 17:04:51   word_dropout         0.0
07/22 17:04:52 python random seed: 3077377043715698341
07/22 17:04:52 tf random seed:     7636467340656823648
07/22 17:04:52 creating model
07/22 17:04:52 using device: /gpu:6
07/22 17:04:52 copying vocab to ../emse-data/model/hybrid\data\vocab.code
07/22 17:04:52 copying vocab to ../emse-data/model/hybrid\data\vocab.sbt
